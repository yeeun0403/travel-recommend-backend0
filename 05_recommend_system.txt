def recommend_places(user_input, tfidf_vectorizer, season_model, nature_model, vibe_model, target_model, df, top_n=3):
    # 1. ì‚¬ìš©ì ì…ë ¥ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
    combined_input = ' '.join([
        user_input['season']] +
        user_input['nature'] +
        user_input['vibe'] +
        user_input['target']
    )
     # 2. TF-IDF ë²¡í„°í™”
    user_vec = tfidf_vectorizer.transform([combined_input])

    # 3. ê° ëª¨ë¸ì—ì„œ ì˜ˆì¸¡
    season_pred = season_model.predict(user_vec)
    nature_pred = nature_model.predict(user_vec)
    vibe_pred = vibe_model.predict(user_vec)
    target_pred = target_model.predict(user_vec)

    # 4. ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°: ê´€ê´‘ì§€ descriptionì„ ë²¡í„°í™”
    place_vecs = tfidf_vectorizer.transform(df['description'])

    scores = []
    for i in range(len(df)):
        score = 0
        place_row = df.iloc[i]

        # season ë¹„êµ
        score += int(place_row['season'] == user_input['season'])

        # nature, vibe, target: ê²¹ì¹˜ëŠ” íƒœê·¸ ìˆ˜
        for key, pred in zip(['nature', 'vibe', 'target'], [nature_pred, vibe_pred, target_pred]):
            pred_tags = [tag for tag, val in zip(df.columns, pred[0]) if val == 1]
            actual_tags = place_row[key].split(',')
            overlap = len(set(pred_tags) & set(actual_tags))
            score += overlap

        scores.append((i, score))

    # 5. Top-N ì ìˆ˜ ë†’ì€ ê´€ê´‘ì§€ ì¶œë ¥
    top_indices = sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]
    recommendations = df.iloc[[idx for idx, _ in top_indices]]
    return recommendations[['name', 'city', 'description']]

# !pip install ace_tools
# !pip install matplotlib-venn
# !apt-get -qq install -y libfluidsynth1
# !apt-get -qq install -y libarchive-dev && pip install -U libarchive
# import libarchive
# !apt-get -qq install -y graphviz && pip install pydot
# import pydot
# !pip install cartopy
# import cartopy

# ëŸ°íƒ€ì„ ì´ˆê¸°í™”ë¡œ ëª¨ë“  ë³€ìˆ˜ ì¬ì •ì˜ í•„ìš”
# ë‹¤ì‹œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ë° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier
from sklearn.pipeline import make_pipeline
from google.colab import drive
drive.mount('/content/drive')
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path = '/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/ê°•ì›ë„_ê´€ê´‘ì§€_20_ì˜ˆì‹œ.xlsx'
df = pd.read_excel(file_path)

# TF-IDF ë²¡í„°ë¼ì´ì € í•™ìŠµ (description ê¸°ë°˜)
tfidf_vectorizer = TfidfVectorizer(max_features=1000)
X_all = tfidf_vectorizer.fit_transform(df['description'])

# season ë‹¨ì¼ ë¶„ë¥˜ê¸° í•™ìŠµ
le_season = LabelEncoder()
y_season = le_season.fit_transform(df['season'])
# Removed TfidfVectorizer from season_model pipeline
season_model = LogisticRegression(max_iter=1000)
season_model.fit(X_all, y_season)

# nature ë¶„ë¥˜ê¸° í•™ìŠµ
df['nature'] = df['nature'].apply(lambda x: [t.strip() for t in str(x).split(',')])
mlb_nature = MultiLabelBinarizer()
y_nature = mlb_nature.fit_transform(df['nature'])
nature_model = OneVsRestClassifier(LogisticRegression(max_iter=1000))
nature_model.fit(X_all, y_nature)

# vibe ë¶„ë¥˜ê¸° í•™ìŠµ
df['vibe'] = df['vibe'].apply(lambda x: [t.strip() for t in str(x).split(',')])
mlb_vibe = MultiLabelBinarizer()
y_vibe = mlb_vibe.fit_transform(df['vibe'])
vibe_model = OneVsRestClassifier(LogisticRegression(max_iter=1000))
vibe_model.fit(X_all, y_vibe)

# target ë¶„ë¥˜ê¸° í•™ìŠµ
df['target'] = df['target'].apply(lambda x: [t.strip() for t in str(x).split(',')])
mlb_target = MultiLabelBinarizer()
y_target = mlb_target.fit_transform(df['target'])
target_model = OneVsRestClassifier(LogisticRegression(max_iter=1000))
target_model.fit(X_all, y_target)

# ì¶”ì²œ í•¨ìˆ˜ ì •ì˜
def recommend_places(user_input, tfidf_vectorizer, season_model, nature_model, vibe_model, target_model, df, top_n=3):
    combined_input = ' '.join([
        user_input['season']] +
        user_input['nature'] +
        user_input['vibe'] +
        user_input['target']
    )
    user_vec = tfidf_vectorizer.transform([combined_input])
    # Pass the already vectorized input to the season_model
    season_pred = season_model.predict(user_vec)
    nature_pred = nature_model.predict(user_vec)
    vibe_pred = vibe_model.predict(user_vec)
    target_pred = target_model.predict(user_vec)

    place_vecs = tfidf_vectorizer.transform(df['description'])
    scores = []
    for i in range(len(df)):
        score = 0
        place_row = df.iloc[i]
        score += int(place_row['season'] == user_input['season'])
        for key, pred, col, mlb in zip(
            ['nature', 'vibe', 'target'],
            [nature_pred, vibe_pred, target_pred],
            ['nature', 'vibe', 'target'],
            [mlb_nature, mlb_vibe, mlb_target]
        ):
            pred_tags = [tag for tag, val in zip(mlb.classes_, pred[0]) if val == 1]
            actual_tags = place_row[col]
            overlap = len(set(pred_tags) & set(actual_tags))
            score += overlap
        scores.append((i, score))
    top_indices = sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]
    recommendations = df.iloc[[idx for idx, _ in top_indices]]
    return recommendations[['name', 'city', 'description']]

# ì‚¬ìš©ì ì…ë ¥ ì˜ˆì‹œ
user_input = {
    "season": "ì—¬ë¦„",
    "nature": ["ë°”ë‹¤", "ìì—°"],
    "vibe": ["ê°ì„±", "ì‚°ì±…"],
    "target": ["ì—°ì¸"]
}

# ì¶”ì²œ ì‹¤í–‰
# ì¶”ì²œ ê²°ê³¼ ì¶œë ¥
recommendations = recommend_places(
    user_input=user_input,
    tfidf_vectorizer=tfidf_vectorizer,
    season_model=season_model,
    nature_model=nature_model,
    vibe_model=vibe_model,
    target_model=target_model,
    df=df,
    top_n=3
)

# ê²°ê³¼ ë³´ê¸°
print("ğŸ¯ ì¶”ì²œëœ ê´€ê´‘ì§€ ëª©ë¡:")
display(recommendations[['name', 'city', 'description']])

import pandas as pd
import joblib
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression

# íŒŒì¼ ê²½ë¡œ
file_path = '/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/ê°•ì›ë„_ê´€ê´‘ì§€_20_ì˜ˆì‹œ.xlsx'
df = pd.read_excel(file_path)

# TF-IDF ë²¡í„°ë¼ì´ì € ë¡œë”©
vectorizer = joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/tfidf_vectorizer.pkl')
X_vec = vectorizer.transform(df['description'])

# ì‚¬ìš©ì ì…ë ¥ (ì˜ˆì‹œ)
user_input = {
    'season': 'ê°€ì„',
    'nature': 'ì‚°',
    'vibe': 'í•œì í•œ',
    'target': 'ì—°ì¸'
}

# ëª¨ë¸ ë° ì¸ì½”ë” ë¶ˆëŸ¬ì˜¤ê¸°
models = {
    'season': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/season_model.pkl'),
    'nature': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/nature_model.pkl'),
    'vibe': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/vibe_model.pkl'),
    'target': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/target_model.pkl'),
}
encoders = {
    'season': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/season_encoder.pkl'),
    'nature': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/nature_encoder.pkl'),
    'vibe': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/vibe_encoder.pkl'),
    'target': joblib.load('/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/target_encoder.pkl'),
}

# **Fit the loaded models with the data before making predictions**
# Assuming you have the target variables for nature, vibe, and target available
# Based on the previous cell, it seems you have the processed target variables y_nature, y_vibe, y_target
# You would need to load or regenerate these as well if they are not part of the saved models/encoders
# For demonstration, let's assume y_nature, y_vibe, y_target are available from previous steps or loaded from files.
# If not, you would need to add code to generate them here.

# Example of how to generate y_nature, y_vibe, y_target if not loaded:
# df['nature'] = df['nature'].apply(lambda x: [t.strip() for t in str(x).split(',')])
# mlb_nature = MultiLabelBinarizer()
# y_nature = mlb_nature.fit_transform(df['nature'])
# df['vibe'] = df['vibe'].apply(lambda x: [t.strip() for t in str(x).split(',')])
# mlb_vibe = MultiLabelBinarizer()
# y_vibe = mlb_vibe.fit_transform(df['vibe'])
# df['target'] = df['target'].apply(lambda x: [t.strip() for t in str(x).split(',')])
# mlb_target = MultiLabelBinarizer()
# y_target = mlb_target.fit_transform(df['target'])


# Since the previous cell re-generated these, we can assume they are available in the environment
# if the notebook is run sequentially. If running this cell in isolation, you'd need to load/generate them.

# Fit the loaded models:
# models['season'].fit(X_vec, encoders['season'].transform(df['season'])) # Season model is LogisticRegression
# models['nature'].fit(X_vec, y_nature) # Assuming y_nature is available
# models['vibe'].fit(X_vec, y_vibe)   # Assuming y_vibe is available
# models['target'].fit(X_vec, y_target) # Assuming y_target is available

# NOTE: If you saved the fitted models, you don't need to fit them again.
# The error suggests they were not fitted *after loading*.
# A better approach is to save the *fitted* models.
# Let's assume the models saved were unfitted, and fit them here:
# If your saved models were already fitted, you should remove these fit lines.
# Based on the error, it seems the loaded models need fitting.

# To make this cell runnable independently, let's regenerate the target variables and fit the models
# This mirrors the process in the successful cell `rEt6iSdYmvvV` but uses the loaded models.

df['season'] = df['season'].astype(str) # Ensure season is string
df['nature'] = df['nature'].apply(lambda x: [t.strip() for t in str(x).split(',')])
df['vibe'] = df['vibe'].apply(lambda x: [t.strip() for t in str(x).split(',')])
df['target'] = df['target'].apply(lambda x: [t.strip() for t in str(x).split(',')])

# Regenerate encoders and target variables for fitting
le_season = LabelEncoder()
y_season = le_season.fit_transform(df['season'])

mlb_nature = MultiLabelBinarizer()
y_nature = mlb_nature.fit_transform(df['nature'])

mlb_vibe = MultiLabelBinarizer()
y_vibe = mlb_vibe.fit_transform(df['vibe'])

mlb_target = MultiLabelBinarizer()
y_target = mlb_target.fit_transform(df['target'])

# Fit the loaded models with the data
models['season'].fit(X_vec, y_season)
models['nature'].fit(X_vec, y_nature)
models['vibe'].fit(X_vec, y_vibe)
models['target'].fit(X_vec, y_target)


# ê° ë¶„ë¥˜ê¸°ì—ì„œ í™•ë¥  ì˜ˆì¸¡
weights = {
    'season': 1.0,
    'nature': 1.0,
    'vibe': 1.0,
    'target': 1.0
}

total_scores = np.zeros(X_vec.shape[0])

for key in ['season', 'nature', 'vibe', 'target']:
    model = models[key]
    encoder = encoders[key]
    # For multi-label models (nature, vibe, target), the encoder is MultiLabelBinarizer
    # We need to find the column index for the user input tag(s) in the binarized output
    if key in ['nature', 'vibe', 'target']:
        # For multi-label, user_input[key] can be a list of tags
        # We need to find the indices of these tags in the mlb.classes_
        user_tags = [user_input[key]] if isinstance(user_input[key], str) else user_input[key]
        tag_indices = [i for i, tag in enumerate(encoder.classes_) if tag in user_tags]
        if tag_indices:
            # Sum probabilities for all matched tags in multi-label case
            probas = np.sum(model.predict_proba(X_vec)[:, tag_indices], axis=1)
        else:
            # If no matching tag, probabilities are zero
            probas = np.zeros(X_vec.shape[0])
    else: # For single-label model (season)
        label_index = encoder.transform([user_input[key]])[0]
        probas = model.predict_proba(X_vec)[:, label_index]

    total_scores += weights[key] * probas

# Top-N ê´€ê´‘ì§€ ì¶”ì²œ
df['ì¶”ì²œì ìˆ˜'] = total_scores
recommendations = df.sort_values(by='ì¶”ì²œì ìˆ˜', ascending=False).head(3)

# ê²°ê³¼ ì¶œë ¥
print("ğŸ” ì‚¬ìš©ì ì…ë ¥:", user_input)
print("ğŸ¯ ì¶”ì²œ ê²°ê³¼:")
display(recommendations[['name', 'ì¶”ì²œì ìˆ˜']])

import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer # Import necessary classes
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression

# ê²½ë¡œ ì„¤ì •
base_path = '/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/'  # Colabì—ì„œëŠ” ì´ ê²½ë¡œ ìœ ì§€
file_path = base_path + 'ê°•ì›ë„_ê´€ê´‘ì§€_20_ì˜ˆì‹œ.xlsx'

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_excel(file_path)

# TF-IDF ë²¡í„°ë¼ì´ì € ë° ëª¨ë¸ ë¡œë”©
vectorizer = joblib.load(base_path + 'tfidf_vectorizer.pkl')
models = {
    'season': joblib.load(base_path + 'season_model.pkl'),
    'nature': joblib.load(base_path + 'nature_model.pkl'),
    'vibe': joblib.load(base_path + 'vibe_model.pkl'),
    'target': joblib.load(base_path + 'target_model.pkl'),
}
encoders = {
    'season': joblib.load(base_path + 'season_encoder.pkl'),
    'nature': joblib.load(base_path + 'nature_encoder.pkl'),
    'vibe': joblib.load(base_path + 'vibe_encoder.pkl'),
    'target': joblib.load(base_path + 'target_encoder.pkl'),
}

# TF-IDF ë²¡í„°í™”
X_vec = vectorizer.transform(df['description'])

# Prepare target variables for fitting the loaded models
df['season'] = df['season'].astype(str)
df['nature'] = df['nature'].apply(lambda x: [t.strip() for t in str(x).split(',')])
df['vibe'] = df['vibe'].apply(lambda x: [t.strip() for t in str(x).split(',')])
df['target'] = df['target'].apply(lambda x: [t.strip() for t in str(x).split(',')])

# Regenerate target variables for fitting
# Note: If the saved models were already fitted, you would not need this step.
# Based on the error, it seems the loaded models require fitting.
le_season = LabelEncoder()
y_season = le_season.fit_transform(df['season'])

mlb_nature = MultiLabelBinarizer()
y_nature = mlb_nature.fit_transform(df['nature'])

mlb_vibe = MultiLabelBinarizer()
y_vibe = mlb_vibe.fit_transform(df['vibe'])

mlb_target = MultiLabelBinarizer()
y_target = mlb_target.fit_transform(df['target'])


# Fit the loaded models with the data
models['season'].fit(X_vec, y_season)
models['nature'].fit(X_vec, y_nature)
models['vibe'].fit(X_vec, y_vibe)
models['target'].fit(X_vec, y_target)


# ì‚¬ìš©ì ì…ë ¥ ì˜ˆì‹œ
user_input = {
    'season': 'ê°€ì„',
    'nature': ['ì‚°', 'ìì—°'],
    'vibe': ['ê°ì„±', 'í•œì í•œ'],
    'target': ['ì—°ì¸']
}

# ì˜ˆì¸¡ ì ìˆ˜ ê³„ì‚°
weights = {'season': 1.0, 'nature': 1.0, 'vibe': 1.0, 'target': 1.0}
total_scores = np.zeros(X_vec.shape[0])

for key in ['season', 'nature', 'vibe', 'target']:
    model = models[key]
    encoder = encoders[key]

    if key == 'season':
        label_index = encoder.transform([user_input[key]])[0]
        probas = model.predict_proba(X_vec)[:, label_index]
    else:
        user_tags = [user_input[key]] if isinstance(user_input[key], str) else user_input[key]
        tag_indices = [i for i, tag in enumerate(encoder.classes_) if tag in user_tags]
        probas = np.sum(model.predict_proba(X_vec)[:, tag_indices], axis=1) if tag_indices else np.zeros(X_vec.shape[0])

    total_scores += weights[key] * probas

# Top-3 ê´€ê´‘ì§€ ì¶”ì²œ
df['ì¶”ì²œì ìˆ˜'] = total_scores
recommendations = df.sort_values(by='ì¶”ì²œì ìˆ˜', ascending=False).head(3)[['name', 'city', 'description', 'ì¶”ì²œì ìˆ˜']]

# ê²°ê³¼ ì¶œë ¥
print("ğŸ¯ ì¶”ì²œëœ ê´€ê´‘ì§€ Top 3")
print(recommendations.to_string(index=False))


